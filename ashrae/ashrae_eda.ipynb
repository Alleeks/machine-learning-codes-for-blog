{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのimport\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 150) # pandas dataframe表示列数の設定\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import seaborn as sns\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import datetime as dt\n",
    "\n",
    "import os, random, math, psutil, pickle\n",
    "\n",
    "# kaggle kernelの利用を想定しています。\n",
    "# ローカルなど、別環境で作業する場合はファイルを置いたディレクトリを指定してください\n",
    "print(os.listdir('../input/ashrae-energy-prediction/')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%timeはセルの実行時間を計測\n",
    "\n",
    "# データの読み込み\n",
    "train_df = pd.read_csv('../input/ashrae-energy-prediction/train.csv')\n",
    "test_df = pd.read_csv('../input/ashrae-energy-prediction/test.csv')\n",
    "weather_train_df = pd.read_csv('../input/ashrae-energy-prediction/weather_train.csv')\n",
    "weather_test_df = pd.read_csv('../input/ashrae-energy-prediction/weather_test.csv')\n",
    "building_meta_df = pd.read_csv('../input/ashrae-energy-prediction/building_metadata.csv')\n",
    "sample_submission = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv')\n",
    "\n",
    "# 文字列をTimestamp型に変換（日時情報の処理をしやすくするためです）\n",
    "train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\n",
    "test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "weather_train_df['timestamp'] = pd.to_datetime(weather_train_df['timestamp'])\n",
    "weather_test_df['timestamp'] = pd.to_datetime(weather_test_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum()/1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            print(col)\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = reduce_mem_usage(train_df, use_float16=True)\n",
    "building_meta_df = reduce_mem_usage(building_meta_df, use_float16=True)\n",
    "weather_train_df = reduce_mem_usage(weather_train_df, use_float16=True)\n",
    "weather_test_df = reduce_mem_usage(weather_test_df, use_float16=True)\n",
    "sample_submission = reduce_mem_usage(sample_submission, use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dfもほぼ同じ形状(meter_readingカラムがないだけ)なので省略\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_test_dfは同じ形状\n",
    "weather_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe形状の確認\n",
    "print('train_df 形状: ', train_df.shape)\n",
    "print('test_df 形状: ', test_df.shape)\n",
    "print('building_meta_df 形状: ', building_meta_df.shape)\n",
    "print('weather_train_df 形状: ', weather_train_df.shape)\n",
    "print('weather_test_df 形状: ', weather_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値（の割合）確認\n",
    "train_df.count()/len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.count()/len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_built/floor_countに欠損が見られる\n",
    "building_meta_df.count()/len(building_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/testどちらのデータでもsite_id/timestamp以外のカラムに欠損が見られます\n",
    "weather_train_df.count()/len(weather_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test_df.count()/len(weather_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframeの結合\n",
    "train_df = train_df.merge(building_meta_df, on='building_id', how='left')\n",
    "test_df = test_df.merge(building_meta_df, on='building_id', how='left')\n",
    "\n",
    "train_df = train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n",
    "test_df = test_df.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "# delで削除して、gc.collect()ですぐにメモリを解放する\n",
    "del weather_train_df, weather_test_df, building_meta_df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(12, 4), dpi=100)\n",
    "# 1時間毎の平均の消費量について可視化\n",
    "train_df[['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes, label='By hour', alpha=0.8).set_ylabel('Meter reading', fontsize=14);\n",
    "# 1日毎の平均の消費量について可視化\n",
    "train_df[['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes, label='By day', alpha=1).set_ylabel('Meter reading', fontsize=14);\n",
    "\n",
    "axes.set_title('Mean Meter reading by hour and day', fontsize=16);\n",
    "axes.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siteごとに可視化する。15siteあるので8x2で表示するようにします。\n",
    "fig, axes = plt.subplots(8, 2, figsize=(12, 28), dpi=100)\n",
    "# site_idの値でループ\n",
    "for i in range(train_df['site_id'].nunique()):\n",
    "    # site_id = iのデータを取得\n",
    "    train_df[train_df['site_id'] == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i//8], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\n",
    "    train_df[train_df['site_id'] == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%8][i//8], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n",
    "    axes[i%8][i//8].legend();\n",
    "    axes[i%8][i//8].set_title('site_id {}'.format(i), fontsize=13);\n",
    "    plt.subplots_adjust(hspace=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8, 2, figsize=(10, 18), dpi=100)\n",
    "# value_counts()のindexをリスト化\n",
    "for i, use in enumerate(train_df['primary_use'].value_counts().index.to_list()):\n",
    "    try:\n",
    "        train_df[(train_df['site_id']==13) & (train_df['primary_use'] == use)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i//8], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=7);\n",
    "        train_df[(train_df['site_id']==13) & (train_df['primary_use'] == use)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%8][i//8], alpha=1, label='By day', color='tab:orange').set_xlabel();\n",
    "        axes[i%8][i//8].legend();\n",
    "    except TypeError:\n",
    "        pass\n",
    "    axes[i%8][i//8].set_title(use, fontsize=7);\n",
    "    plt.subplots_adjust(hspace=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(5, 7), dpi=100)\n",
    "for i in train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') ]['meter'].value_counts(dropna=False).index.to_list():\n",
    "    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == i)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=6);\n",
    "    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == i)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n",
    "    axes[i].legend();\n",
    "    axes[i].set_title('Meter: '+ str(i), fontsize=5);\n",
    "    plt.subplots_adjust(hspace=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(9, 2, figsize=(10, 20), dpi=100)\n",
    "for i, build in enumerate(train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2)]['building_id'].value_counts(dropna=False).index.to_list()):\n",
    "    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2) & (train_df['building_id'] == build)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%9][i//9], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=6);\n",
    "    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2) & (train_df['building_id'] == build)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%9][i//9], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n",
    "    axes[i%9][i//9].legend();\n",
    "    axes[i%9][i//9].set_title('Meter: '+ str(build), fontsize=5);\n",
    "    plt.subplots_adjust(hspace=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup(df, interval=24):\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df['month'] = df.datetime.dt.month      \n",
    "    df['day'] = df.datetime.dt.day      \n",
    "    df['hour'] = df.datetime.dt.hour       \n",
    "    # 異常データの削除(Discussionで情報共有)      \n",
    "    df = df[df['building_id'] != 1099]      \n",
    "    df = df[~((df.building_id<=104) & (df.meter==0) & ((df.month<=5) & (df.day<=20)))]                   \n",
    "\n",
    "    # meter_reading=0のデータをmeterごとにbooleanで持つ\n",
    "    is_electric = (df.meter==0) & (df.meter_reading==0)\n",
    "    is_chilledwater = (df.meter==1) & (df.meter_reading==0)\n",
    "    is_steam = (df.meter==2) & (df.meter_reading==0)\n",
    "    is_hotwater = (df.meter==3) & (df.meter_reading==0)\n",
    "\n",
    "    # electric(電気)の消費量が0になるのは、時期に限らずおかしい\n",
    "    bad_electric = df[is_electric].index\n",
    "    df = df.drop(bad_electric, axis=0)\n",
    "    del is_electric, bad_electric\n",
    "    gc.collect()\n",
    "\n",
    "    # shilledwater（冷水）は冬の間は0になっていても問題ないと考える\n",
    "    chilled_transitions = is_chilledwater != is_chilledwater.shift(1)\n",
    "    # 前後のデータと同じかどうか\n",
    "    chilled_sequence = chilled_transitions.cumsum()\n",
    "    # 累積和を計算\n",
    "    chilled_ids = chilled_sequence[is_chilledwater].rename('ids')\n",
    "    # 前後連続して0かどうかの情報取得\n",
    "    keep = chilled_ids[(df.datetime>= dt.datetime(2016,1,15)) & (df.datetime <= dt.datetime(2016,12,15))].unique()\n",
    "    # 冬の期間は0でも問題ないので、それ以外を指定する\n",
    "    is_bad = chilled_ids.isin(keep) & (chilled_ids.map(chilled_ids.value_counts() >= 24))\n",
    "    result = is_chilledwater.copy()\n",
    "    result.update(is_bad)\n",
    "    chilled_index = df[result].index\n",
    "    df = df.drop(chilled_index, axis=0)\n",
    "    del is_chilledwater, chilled_transitions, chilled_sequence, chilled_ids, keep, is_bad, result, chilled_index\n",
    "    gc.collect()\n",
    "\n",
    "    # steam(蒸気)、hotwater(温水)は夏の間0でも問題ないと考える\n",
    "    steam_transitions = is_steam != is_steam.shift(1)\n",
    "    steam_sequence = steam_transitions.cumsum()\n",
    "    steam_ids = steam_sequence[is_steam].rename('ids')\n",
    "    keep = steam_ids[(df.datetime <= dt.datetime(2016,8,1)) | (df.datetime >= dt.datetime(2016,8,31))].unique()\n",
    "    is_bad = steam_ids.isin(keep) & (steam_ids.map(steam_ids.value_counts()>=24))\n",
    "    result = is_steam.copy() \n",
    "    result.update(is_bad)\n",
    "    steam_index = df[result].index\n",
    "    df = df.drop(steam_index, axis=0)\n",
    "    del is_steam, steam_transitions, steam_sequence, steam_ids, keep, is_bad, result, steam_index\n",
    "    gc.collect()\n",
    "\n",
    "    hotwater_transitions = is_hotwater != is_hotwater.shift(1)\n",
    "    hotwater_sequence = hotwater_transitions.cumsum()\n",
    "    hotwater_ids = hotwater_sequence[is_hotwater].rename('ids')\n",
    "    keep = hotwater_ids[(df.datetime <= dt.datetime(2016,8,1)) | (df.datetime >= dt.datetime(2016,8,31))].unique()\n",
    "    is_bad = hotwater_ids.isin(keep) & (hotwater_ids.map(hotwater_ids.value_counts()>=24))\n",
    "    result = is_hotwater.copy()\n",
    "    result.update(is_bad)\n",
    "    hotwater_index = df[result].index\n",
    "    df = df.drop(hotwater_index, axis=0)\n",
    "    df = df.drop(['month', 'day', 'hour', 'datetime'], axis=1)\n",
    "    del is_hotwater, hotwater_transitions, hotwater_sequence, hotwater_ids, keep, is_bad, result, hotwater_index\n",
    "    gc.collect()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainデータでの'meter'の出現頻度を抽出\n",
    "train_data = train_df['meter'].value_counts(dropna=False, normalize=True).sort_index().values\n",
    "ind = np.arange(len(train_data))\n",
    "width = 0.35\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(14, 6), dpi=100)\n",
    "tr = axes.bar(ind, train_data, width, color='royalblue')\n",
    "# testデータでの'meter'の出現頻度を抽出\n",
    "test_data = test_df['meter'].value_counts(dropna=False, normalize=True).sort_index().values\n",
    "tt = axes.bar(ind+width, test_data, width, color='seagreen')\n",
    "\n",
    "axes.set_ylabel('Normalized number of observations');\n",
    "axes.set_xlabel('meter type');\n",
    "axes.set_xticks(ind + width / 2)\n",
    "\n",
    "axes.set_xticklabels(train_df['meter'].value_counts().sort_index().index, rotation=0)\n",
    "axes2 = axes.twinx()\n",
    "\n",
    "# 'meter'でグループ化して、'meter_reading'の平均を計算\n",
    "mr = axes2.plot(ind, train_df[['meter', 'meter_reading']].groupby('meter')['meter_reading'].mean().sort_index().values, 'D-', color='tab:orange', label='Mean meter reading');\n",
    "axes2.grid(False);\n",
    "axes2.tick_params(axis='y', labelcolor='tab:orange');\n",
    "axes2.set_ylabel('Mean meter reading by meter type', color='tab:orange');\n",
    "axes.legend([tr, tt], ['Train', 'Test'], facecolor='white');\n",
    "axes2.legend(loc=5, facecolor='white');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site(地域)ごとではなく、全体として確認する\n",
    "fig, axes = plt.subplots(1,1,figsize=(14, 6), dpi=100)\n",
    "# train_dfから'timestamp'と'air_temperature'カラムを取得し、'timestamp'\n",
    "train_df[['timestamp', 'air_temperature']].set_index('timestamp').resample('H').mean()['air_temperature'].plot(ax=axes, alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean temperature', fontsize=14);\n",
    "test_df[['timestamp', 'air_temperature']].set_index('timestamp').resample('H').mean()['air_temperature'].plot(ax=axes, alpha=0.8, color='tab:blue', label='');\n",
    "train_df[['timestamp', 'air_temperature']].set_index('timestamp').resample('D').mean()['air_temperature'].plot(ax=axes, alpha=1, label='By day', color='tab:orange');\n",
    "test_df[['timestamp', 'air_temperature']].set_index('timestamp').resample('D').mean()['air_temperature'].plot(ax=axes, alpha=1, color='tab:orange', label='');\n",
    "axes.legend();\n",
    "axes.text(train_df['timestamp'].iloc[9000000], -3, 'Train', fontsize=16);\n",
    "axes.text(test_df['timestamp'].iloc[29400000], 30, 'Test', fontsize=16);\n",
    "axes.axvspan(test_df['timestamp'].min(), test_df['timestamp'].max(), facecolor='green', alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siteごとに確認する\n",
    "fig, axes = plt.subplots(8, 2, figsize=(14, 30), dpi=100)\n",
    "# site_idのidでループを回す\n",
    "for i in range(train_df['site_id'].nunique()):\n",
    "    train_df[train_df['site_id']==i][['timestamp', 'air_temperature']].set_index('timestamp').resample('H').mean()['air_temperature'].plot(ax=axes[i%8][i//8], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean temperature', fontsize=13);\n",
    "    test_df[test_df['site_id']==i][['timestamp', 'air_temperature']].set_index('timestamp').resample('H').mean()['air_temperature'].plot(ax=axes[i%8][i//8], alpha=0.8, color='tab:blue', label='').set_xlabel('')\n",
    "    train_df[train_df['site_id']==i][['timestamp', 'air_temperature']].set_index('timestamp').resample('D').mean()['air_temperature'].plot(ax=axes[i%8][i//8], alpha=1, label='By day', color='tab:orange')\n",
    "    test_df[test_df['site_id']==i][['timestamp', 'air_temperature']].set_index('timestamp').resample('D').mean()['air_temperature'].plot(ax=axes[i%8][i//8], alpha=1, color='tab:orange', label='').set_xlabel('')\n",
    "    axes[i%8][i//8].legend()\n",
    "    axes[i%8][i//8].set_title('site_id {}'.format(i), fontsize=13);\n",
    "    axes[i%8][i//8].axvspan(test_df['timestamp'].min(), test_df['timestamp'].max(), facecolor='green', alpha=0.2);\n",
    "    plt.subplots_adjust(hspace=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 気象情報のみで補間してみます\n",
    "# weather_train/test_dfは先ほど、削除してしまったので、改めて読み込みます\n",
    "weather_train_df = pd.read_csv('../input/ashrae-energy-prediction/weather_train.csv')\n",
    "weather_test_df = pd.read_csv('../input/ashrae-energy-prediction/weather_test.csv')\n",
    "\n",
    "weather_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train期間中のair_temperatureの欠損数: ', len(weather_train_df[weather_train_df.air_temperature.isnull()==True]))\n",
    "print('test期間中のair_temperatureの欠損数: ', len(weather_test_df[weather_test_df.air_temperature.isnull()==True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間情報を利用しやすくするためのデータの型変換\n",
    "weather_train_df['timestamp'] = pd.to_datetime(weather_train_df['timestamp'])\n",
    "weather_test_df['timestamp'] = pd.to_datetime(weather_test_df['timestamp'])\n",
    "\n",
    "# 気温は月・日・時の影響を受けると思われるので、特徴量を追加します\n",
    "weather_train_df['hour'] = weather_train_df['timestamp'].dt.hour\n",
    "weather_train_df['day'] = weather_train_df['timestamp'].dt.day\n",
    "weather_train_df['month'] = weather_train_df['timestamp'].dt.month\n",
    "\n",
    "weather_test_df['hour'] = weather_test_df['timestamp'].dt.hour\n",
    "weather_test_df['day'] = weather_test_df['timestamp'].dt.day\n",
    "weather_test_df['month'] = weather_test_df['timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X:欠損がないデータ　X_dash:欠損があるデータ\n",
    "X = weather_train_df[weather_train_df.air_temperature.isnull()==False]\n",
    "X_dash = weather_train_df[weather_train_df.air_temperature.isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測（補間）する対象を目的変数として、yで定義する\n",
    "y = X['air_temperature'].values\n",
    "\n",
    "# 今回は、説明変数として['site_id', 'hour', 'day', 'month']だけを用います（場所と時間）\n",
    "x = X[['site_id', 'hour', 'day', 'month']].values\n",
    "x_dash = X_dash[['site_id', 'hour', 'day', 'month']].values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression() # インスタンスの作成\n",
    "\n",
    "lr.fit(x, y) # 説明変数と真の目的変数を与えて、回帰モデルの学習s\n",
    "predict_y = lr.predict(x_dash)\n",
    "\n",
    "# X_dashの\"air_temperature\"カラムの値を予測値で置き換える\n",
    "X_dash['air_temperature'] = predict_y\n",
    "\n",
    "# dataframeを結合すれば、元のweather_train_dfと同じ形状で、'air_temperature'カラムが補間されたデータが作成できます\n",
    "df = pd.concat([X, X_dash]) # ==(nearly equal) weather_train_df\n",
    "\n",
    "del X, X_dash, predict_y\n",
    "gc.collect()\n",
    "\n",
    "# testデータでは、学習は行わず、予測だけ行います\n",
    "X = weather_test_df[weather_test_df.air_temperature.isnull()==False] \n",
    "X_dash = weather_test_df[weather_test_df.air_temperature.isnull()==True] #欠損があるもの\n",
    "\n",
    "x_dash = X_dash[['site_id', 'hour', 'day', 'month']].values\n",
    "\n",
    "predict_y = lr.predict(x_dash)\n",
    "\n",
    "X_dash['air_temperature'] = predict_y\n",
    "\n",
    "df_dash = pd.concat([X, X_dash])\n",
    "\n",
    "del X, X_dash, predict_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 月\n",
    "train_df['month'] = train_df['timestamp'].dt.month\n",
    "test_df['month'] = test_df['timestamp'].dt.month\n",
    "# 日\n",
    "train_df['day'] = train_df['timestamp'].dt.day\n",
    "test_df['day'] = test_df['timestamp'].dt.day\n",
    "# 時\n",
    "train_df['hour'] = train_df['timestamp'].dt.hour\n",
    "test_df['hour'] = test_df['timestamp'].dt.hour\n",
    "# 曜日\n",
    "train_df['weekday'] = train_df['timestamp'].dt.weekday\n",
    "test_df['weekday'] = test_df['timestamp'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df['hour'].value_counts(dropna=False, normalize=True).sort_index().values\n",
    "ind = np.arange(len(train_data))\n",
    "width = 0.35\n",
    "\n",
    "fig, axes = plt.subplots(1,1,figsize=(14, 6), dpi=100)\n",
    "tr = axes.bar(ind, train_data, width, color='royalblue')\n",
    "\n",
    "test_data = test_df['hour'].value_counts(dropna=False, normalize=True).sort_index().values\n",
    "tt = axes.bar(ind+width, test_data, width, color='seagreen')\n",
    "\n",
    "axes.set_ylabel('Normalized number of observations');\n",
    "axes.set_xlabel('Hour');\n",
    "axes.set_xticks(ind + width / 2)\n",
    "axes.set_xticklabels(train_df['hour'].value_counts().sort_index().index, rotation=0)\n",
    "axes2 = axes.twinx()\n",
    "mr = axes2.plot(ind, train_df[['hour', 'meter_reading']].groupby('hour')['meter_reading'].mean().sort_index().values, 'D-', color='tab:orange', label='Mean meter reading');\n",
    "axes2.grid(False);\n",
    "axes2.tick_params(axis='y', labelcolor='tab:orange');\n",
    "axes2.set_ylabel('Mean meter reading by hour', color='tab:orange');\n",
    "axes.legend([tr, tt], ['Train', 'Test'], facecolor='white');\n",
    "axes2.legend(loc=2, facecolor='white');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_idと地域を結びつけるdictionary\n",
    "country = {0:1,1:2,2:1,3:1,4:1,5:2,6:1,7:3,8:1,9:1,10:1,11:3,12:4,13:1,14:1,15:1} \n",
    "train_df['country'] = train_df['site_id'].map(country) \n",
    "# siteとGMT（グリニッジ標準時）との差（だと思います）\n",
    "timediff = {0:4,1:0,2:7,3:4,4:7,5:0,6:4,7:4,8:4,9:5,10:7,11:4,12:0,13:5,14:4,15:4} \n",
    "train_df['time_diff']= train_df['site_id'].map(timediff)\n",
    "\n",
    "# GMTとの差の情報を用いて'hour'カラムの値を変換\n",
    "train_df['hour'] = train_df['hour'] + train_df['time_diff'] \n",
    "train_df.loc[train_df['hour']>23, 'hour'] = train_df[train_df['hour']>23]['hour'] - 24"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
