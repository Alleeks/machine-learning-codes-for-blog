{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering編での特徴量の処理を完了していることを前提としています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メインモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['meter_reading']\n",
    "features = train_df.drop('meter_reading', axis=1)\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリを表す特徴量を指定（以下の特徴は数値で表現してありますが、それらは数値の大小は関係なく、単に種類を表しています）\n",
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", 'building_meter_category', 'primary_use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective: タスク種別の指定（回帰、2値分類、多クラス分類など）\n",
    "# num_leaves: 用いる決定木の個数。小さすぎると学習が足りず、大きすぎると過学習に繋がる恐れがあります\n",
    "# learning_rate: 学習率\n",
    "# metric: 誤差定義\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 1300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Foldでデータセットを何分割するか指定します(今回は3セット)\n",
    "kf = KFold(n_splits=3)\n",
    "# データセットの分割数分モデルができるので、そのモデルを格納する入れ物を作成\n",
    "models = []\n",
    "\n",
    "# 指定した分割数で特徴量を分割し、分割数分ループを回しながら学習します\n",
    "# kf.split()で学習用のデータと検証用のデータのindexが返されます\n",
    "for train_index, test_index in kf.split(features):\n",
    "    # index指定でデータを分けます（目的変数と学習用特徴量それぞれ）\n",
    "    train_features = features.loc[train_index]\n",
    "    train_target = target.loc[train_index]\n",
    "    \n",
    "    test_features = features.loc[test_index]\n",
    "    test_target = target.loc[test_index]\n",
    "    \n",
    "    # lightGBMが学習できる形にします\n",
    "    d_training = lgb.Dataset(train_features, label=train_target, categorical_feature=categorical_features, free_raw_data=False)\n",
    "    d_test = lgb.Dataset(test_features, label=test_target, categorical_feature=categorical_features, free_raw_data=False)\n",
    "    \n",
    "    # lgb.train()で学習用・検証用データを渡し、学習させます\n",
    "    # num_boost_round: ブースティングの反復回数\n",
    "    # verbose_eval: どのくらいの頻度で出力を示すかの指定\n",
    "    # early_stopping_rounds: 検証用のスコアが改善されなくなったら学習を停止させるため（過学習を抑える）\n",
    "    model = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_training, d_test], verbose_eval=25, early_stopping_rounds=50)\n",
    "\n",
    "    # 学習したモデルを格納します\n",
    "    models.append(model)\n",
    "    del train_features, train_target, test_features, test_target, d_training, d_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    # lightGBMのplot_importanceメソッドにmodel学習したmodelを渡します\n",
    "    lgb.plot_importance(model)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../input/ashrae-energy-prediction/test.csv\")\n",
    "row_ids = test_df[\"row_id\"]\n",
    "test_df.drop(\"row_id\", axis=1, inplace=True)\n",
    "test_df = reduce_mem_usage(test_df)\n",
    "\n",
    "test_df = test_df.merge(building_meta_df, left_on=\"building_id\", right_on=\"building_id\", how=\"left\")\n",
    "del building_meta_df\n",
    "gc.collect()\n",
    "\n",
    "weather_df = pd.read_csv(\"../input/ashrae-energy-prediction/weather_test.csv\")\n",
    "weather_df = fill_weather_dataset(weather_df)\n",
    "weather_df = get_meteorological_features(weather_df)\n",
    "weather_df = reduce_mem_usage(weather_df)\n",
    "\n",
    "test_df = test_df.merge(weather_df, how=\"left\", on=[\"timestamp\", \"site_id\"])\n",
    "del weather_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割したモデルでそれぞれ予測した値を格納する入れ物を準備する\n",
    "results = []\n",
    "\n",
    "# モデルはリストとして格納してあり、ループを回すことでそれぞれのモデルを取り出す\n",
    "for model in models:\n",
    "    if results == []:\n",
    "        # 予測値を計算\n",
    "        # 各モデルで予測した平均値を最終的な予測値とするため、モデル数で割った値を保存する\n",
    "        results = model.predict(test_df, num_iteration=model.best_iteration)/ len(models)\n",
    "    else:\n",
    "        results += model.predict(test_df, num_iteration=model.best_iteration)/len(models)\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "del test_df, models\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量エンジニアリングで\"meter_reading\"は対数変換していたため、元に戻す\n",
    "results = np.expm1(results)\n",
    "\n",
    "# データフレーム型に変換し、提出フォーマットを整える\n",
    "results_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(results, 0, a_max=None)})\n",
    "del row_ids, results\n",
    "gc.collect()\n",
    "\n",
    "# csvファイルとして保存する\n",
    "results_df.to_csv(\"submission_noleak.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他の手法\n",
    "### メーターごとのモデル作成方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meter=0のモデルの学習\n",
    "\n",
    "# train_df内のmeter==0に該当するデータのみ抽出してfeatures_0という変数で格納する\n",
    "features_0 = train_df[train_df.meter==0]\n",
    "target_0 = train_df['meter_reading']\n",
    "features_0 = train_df.drop(['meter_reading'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", 'building_meter_category', 'primary_use']\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 1000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "models = []\n",
    "\n",
    "for train_index, test_index in kf.split(features_0):\n",
    "    train_features = features_0.loc[train_index]\n",
    "    train_target = target_0.loc[train_index]\n",
    "    \n",
    "    test_features = features_0.loc[test_index]\n",
    "    test_target = target_0.loc[test_index]\n",
    "    \n",
    "    d_training = lgb.Dataset(train_features, label=train_target, categorical_feature=categorical_features, free_raw_data=False)\n",
    "    d_test = lgb.Dataset(test_features, label=test_target, categorical_feature=categorical_features, free_raw_data=False)\n",
    "    \n",
    "    model = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_training, d_test], verbose_eval=25, early_stopping_rounds=50)\n",
    "\n",
    "    models.append(model)\n",
    "    del train_features, train_target, test_features, test_target, d_training, d_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先にメモリを解放しておきます\n",
    "del train_df, target_0, features_0\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータのうち、meter=0のもののみ抽出する\n",
    "test_0 = test_df[test_df.meter==0]\n",
    "\n",
    "# 抽出したのち'row_id'を取り出す\n",
    "row_ids_0 = test_0[\"row_id\"]\n",
    "test_0 = test_0.drop(['row_id'], axis=1)\n",
    "\n",
    "\n",
    "# モデルはリストとして格納してあり、ループを回すことでそれぞれのモデルを取り出す\n",
    "for model in models:\n",
    "    if results_0 == []:\n",
    "        results_0 = model.predict(test_0, num_iteration=model.best_iteration)/ len(models)\n",
    "    else:\n",
    "        results_0 += model.predict(test_0, num_iteration=model.best_iteration)/len(models)\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "del test_0, models\n",
    "gc.collect()\n",
    "\n",
    "results_0 = np.expm1(results_0)\n",
    "\n",
    "# データフレーム型に変換し、提出フォーマットを整える\n",
    "results0_df = pd.DataFrame({\"row_id\": row_ids_0, \"meter_reading\": np.clip(results_0, 0, a_max=None)})\n",
    "del row_ids_0, results_0\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
